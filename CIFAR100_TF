{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:32:43.660649Z","iopub.execute_input":"2025-11-25T01:32:43.661399Z","iopub.status.idle":"2025-11-25T01:32:43.668035Z","shell.execute_reply.started":"2025-11-25T01:32:43.661372Z","shell.execute_reply":"2025-11-25T01:32:43.667396Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/cifar100/test\n/kaggle/input/cifar100/train\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# CIFAR\n\n**Project Overview**\n\nGoal:\n\nBuild a Custom CNN (no transfer learning) that can classify CIFAR-100 images into 100 classes with ~65% accuracy.\n\nDataset:\n\n\t•\tCIFAR-100: 50k train + 10k test, each image is 32×32 RGB, 100 classes.\n\t•\tExample classes: apple, chair, shark, pickup truck, leopard, etc.\n\nApproach:\n\t\n    1.\tLoad dataset & prepare data pipeline\n\t2.\tCreate augmentations\n\t3.\tBuild CNN with residual blocks, BatchNorm, Dropout\n\t4.\tTrain with smart learning rate schedule\n\t5.\tEvaluate performance\n**","metadata":{}},{"cell_type":"code","source":"# imports\n\nimport tensorflow as tf\nimport numpy as np\nimport math","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:32:57.703449Z","iopub.execute_input":"2025-11-25T01:32:57.703740Z","iopub.status.idle":"2025-11-25T01:32:57.707230Z","shell.execute_reply.started":"2025-11-25T01:32:57.703720Z","shell.execute_reply":"2025-11-25T01:32:57.706585Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import pickle\nimport numpy as np\n\ndef load_cifar100(path):\n    with open(path, 'rb') as f:\n        data = pickle.load(f, encoding='latin1')\n    X = data['data'].reshape(-1, 3, 32, 32).transpose(0,2,3,1)\n    y = np.array(data['fine_labels'])\n    return X, y\n\nx_train, y_train = load_cifar100('/kaggle/input/cifar100/train')\nx_test, y_test   = load_cifar100('/kaggle/input/cifar100/test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:32:59.203142Z","iopub.execute_input":"2025-11-25T01:32:59.203857Z","iopub.status.idle":"2025-11-25T01:32:59.596800Z","shell.execute_reply.started":"2025-11-25T01:32:59.203826Z","shell.execute_reply":"2025-11-25T01:32:59.596178Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"What’s happening:\n\n\t•\ttensorflow → our deep learning framework\n\t•\tlayers, models, regularizers → Keras tools for building CNNs\n    \n\t•\tnumpy → for array math\n\t•\tmath → for cosine learning rate scheduling","metadata":{}},{"cell_type":"markdown","source":"# PART 3 — Hyperparameter","metadata":{}},{"cell_type":"markdown","source":"Concept:\n\nThink of these like dials on a control board:\n\n\t•\tBATCH_SIZE: number of images per step\n\t•\tEPOCHS: how many passes over the training data\n\t•\tMIXUP_ALPHA: controls MixUp augmentation (image blending)\n\t•\tLABEL_SMOOTHING: prevents overconfidence in predictions\n\t•\tWEIGHT_DECAY: small penalty on weights to avoid                   overfitting\n    \n\t•\tLR (Learning Rate): how fast the model learns\n\t•\tMOMENTUM: helps SGD optimizer “remember” direction\n\t•\tWARMUP: slowly increase LR early to stabilize training","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 128\nIMG_SHAPE = (32, 32, 3)\nNUM_CLASSES = 100\nEPOCHS = 200\n\nMIXUP_ALPHA = 0.2\nLABEL_SMOOTHING = 0.1\nWEIGHT_DECAY = 1e-4\n\nINITIAL_LR = 0.1\nMOMENTUM = 0.9\nWARMUP_EPOCHS = 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:46.486382Z","iopub.execute_input":"2025-11-25T01:11:46.486628Z","iopub.status.idle":"2025-11-25T01:11:46.490943Z","shell.execute_reply.started":"2025-11-25T01:11:46.486609Z","shell.execute_reply":"2025-11-25T01:11:46.490313Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# PART 4 — Data Loading\n\nConcept:\n\n\t•\tTensorFlow gives you CIFAR-100 ready to go.\n\t•\tEach x = images, y = class labels.\n\t•\tlabel_mode='fine' → 100 detailed classes (not grouped into 20 superclasses).\n\t•\ttf.squeeze removes unnecessary shape dimensions","metadata":{}},{"cell_type":"code","source":"(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode = 'fine')\ny_train = tf.squeeze(y_train)\ny_test = tf.squeeze(y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:46.491631Z","iopub.execute_input":"2025-11-25T01:11:46.491916Z","iopub.status.idle":"2025-11-25T01:11:51.787523Z","shell.execute_reply.started":"2025-11-25T01:11:46.491898Z","shell.execute_reply":"2025-11-25T01:11:51.786762Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1764033111.757829      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1764033111.758400      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# PART 5 — Data Preprocessing (Train vs Test)\n\nConcept:\n\n\t•\tNormalization: divide by 255 to get pixels between [0,1]\n\t•\tAugmentation (train only): random crop, flip, brightness — makes model more robust\n\t•\tNo augmentation on test data, only normalize","metadata":{}},{"cell_type":"code","source":"def preprocess_train(image, label):\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize_with_crop_or_pad(image, 36, 36)\n    image = tf.image.random_crop(image, [32, 32, 3])\n    image = tf.image.random_flip_left_right(image)\n    return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:51.788401Z","iopub.execute_input":"2025-11-25T01:11:51.788681Z","iopub.status.idle":"2025-11-25T01:11:51.793691Z","shell.execute_reply.started":"2025-11-25T01:11:51.788652Z","shell.execute_reply":"2025-11-25T01:11:51.793045Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Eval Prep\ndef preprocess_eval(image, label):\n    return tf.cast(image, tf.float32) / 255.0, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:51.796008Z","iopub.execute_input":"2025-11-25T01:11:51.796255Z","iopub.status.idle":"2025-11-25T01:11:51.803591Z","shell.execute_reply.started":"2025-11-25T01:11:51.796238Z","shell.execute_reply":"2025-11-25T01:11:51.802966Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# PART 6 — Build the TensorFlow Dataset Pipeline\n\nConcept:\n\n\t•\ttf.data.Dataset efficiently feeds data to GPU.\n\t•\tshuffle prevents the model from memorizing the order.\n\t•\tmap applies your preprocessing function.\n\t•\tprefetch overlaps data loading with GPU work for speed","metadata":{}},{"cell_type":"code","source":"train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\ntrain_ds = train_ds.shuffle(50000)\ntrain_ds = train_ds.map(preprocess_train, num_parallel_calls = tf.data.AUTOTUNE)\ntrain_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\ntest_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\ntest_ds = test_ds.map(preprocess_eval).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:51.804188Z","iopub.execute_input":"2025-11-25T01:11:51.804423Z","iopub.status.idle":"2025-11-25T01:11:52.724081Z","shell.execute_reply.started":"2025-11-25T01:11:51.804391Z","shell.execute_reply":"2025-11-25T01:11:52.723520Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# PART 7 — CNN Building Blocks\n\nConcept:\n\n\t•\tConv2D → extracts features (edges, textures, etc.)\n\t•\tBatchNorm → stabilizes and speeds up learning\n\t•\tReLU → adds non-linearity","metadata":{}},{"cell_type":"code","source":"def conv_bn_relu(x, filters, kernel_size=3, stride=1):\n    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same', use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:52.724772Z","iopub.execute_input":"2025-11-25T01:11:52.724947Z","iopub.status.idle":"2025-11-25T01:11:52.729049Z","shell.execute_reply.started":"2025-11-25T01:11:52.724928Z","shell.execute_reply":"2025-11-25T01:11:52.728323Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# PART 8 — Residual Block\n\nConcept:\n\nResidual blocks = ResNet magic\n\nThey skip connections, letting gradients flow easily through deep networks.\n\nYou can think: “learn the change (residual) instead of starting from scratch each layer\"","metadata":{}},{"cell_type":"code","source":"def residual_block(x, filters, stride=1):\n    shortcut = x\n    out = conv_bn_relu(x, filters, 3, stride)\n    out = layers.Conv2D(filters, 3, padding='same', use_bias=False)(out)\n    out = layers.BatchNormalization()(out)\n\n    # adjust shortcut size if needed\n    if stride != 1 or x.shape[-1] != filters:\n        shortcut = layers.Conv2D(filters, 1, strides=stride, use_bias=False)(shortcut)\n        shortcut = layers.BatchNormalization()(shortcut)\n\n    x = layers.add([out, shortcut])\n    x = layers.ReLU()(x)\n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:52.729714Z","iopub.execute_input":"2025-11-25T01:11:52.729952Z","iopub.status.idle":"2025-11-25T01:11:52.740615Z","shell.execute_reply.started":"2025-11-25T01:11:52.729932Z","shell.execute_reply":"2025-11-25T01:11:52.739885Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# PART 10 — Full CNN Architecture\n\nConcept:\n\n\t•\tDeep stacked residual layers → feature extraction\n\t•\tGlobalAveragePooling + GlobalMaxPooling → captures both mean and extreme features\n\t•\tDense layer → final classifier\n\t•\tSoftmax → converts to probabilities","metadata":{}},{"cell_type":"code","source":"def build_custom_cnn(input_shape=(32,32,3), num_classes=100):\n    inputs = layers.Input(shape=input_shape)\n    x = conv_bn_relu(inputs, 64)\n    x = residual_block(x, 64)\n    x = residual_block(x, 128, stride=2)\n    x = residual_block(x, 256, stride=2)\n    x = residual_block(x, 512, stride=2)\n    x = se_block(x)  # optional\n\n    # Advanced pooling: average + max\n    gap = layers.GlobalAveragePooling2D()(x)\n    gmp = layers.GlobalMaxPooling2D()(x)\n    x = layers.Concatenate()([gap, gmp])\n\n    x = layers.Dropout(0.3)(x)\n    x = layers.Dense(512, activation='relu')(x)\n    x = layers.Dropout(0.3)(x)\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n\n    return models.Model(inputs, outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:52.741310Z","iopub.execute_input":"2025-11-25T01:11:52.741607Z","iopub.status.idle":"2025-11-25T01:11:52.752538Z","shell.execute_reply.started":"2025-11-25T01:11:52.741590Z","shell.execute_reply":"2025-11-25T01:11:52.751981Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# PART 11 — Learning Rate Schedule (Cosine + Warmup\n\nConcept\n:\n\t•\tStarts small (warmup) → prevents exploding gradients early\n\t•\tSlowly decays following a cosine wave — helps convergence\n\t•\tThink of it as “start slow, go fast, then cool down smoothl","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport math\n\nclass WarmUpCosine(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, base_lr, epochs, steps_per_epoch, warmup_epochs=5, name=None):\n        super().__init__()\n        self.base_lr = tf.convert_to_tensor(base_lr, dtype=tf.float32)\n        self.epochs = int(epochs)\n        self.steps_per_epoch = int(steps_per_epoch)\n        self.warmup_steps = tf.cast(warmup_epochs * self.steps_per_epoch, tf.float32)\n        self.total_steps = tf.cast(self.epochs * self.steps_per_epoch, tf.float32)\n        self.name = name or \"WarmUpCosine\"\n\n    def __call__(self, step):\n        # make sure step is float32 tensor\n        step = tf.cast(step, tf.float32)\n\n        # Warmup LR: linear ramp from 0 -> base_lr over warmup_steps\n        # Avoid division by zero if warmup_steps == 0\n        warmup_steps = tf.maximum(self.warmup_steps, 1.0)\n        warmup_lr = self.base_lr * (step / warmup_steps)\n\n        # Cosine decay part (after warmup)\n        progress = (step - self.warmup_steps) / tf.maximum(1.0, (self.total_steps - self.warmup_steps))\n        # clip progress to [0,1]\n        progress = tf.clip_by_value(progress, 0.0, 1.0)\n        cosine_decay = 0.5 * (1.0 + tf.cos(math.pi * progress))\n        cosine_lr = self.base_lr * cosine_decay\n\n        # If step < warmup_steps -> warmup_lr else cosine_lr\n        lr = tf.where(step < self.warmup_steps, warmup_lr, cosine_lr)\n        # if step > total_steps, keep lr at 0 (optional) — here we keep clipped cosine_lr (already clipped)\n        return lr\n\n    def get_config(self):\n        return {\n            \"base_lr\": float(self.base_lr.numpy()) if tf.executing_eagerly() else float(self.base_lr),\n            \"epochs\": self.epochs,\n            \"steps_per_epoch\": self.steps_per_epoch,\n            \"warmup_epochs\": int(self.warmup_steps.numpy() // self.steps_per_epoch) if tf.executing_eagerly() else int(self.warmup_steps / self.steps_per_epoch),\n            \"name\": self.name\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:52.753220Z","iopub.execute_input":"2025-11-25T01:11:52.753775Z","iopub.status.idle":"2025-11-25T01:11:52.765412Z","shell.execute_reply.started":"2025-11-25T01:11:52.753753Z","shell.execute_reply":"2025-11-25T01:11:52.764909Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# steps_per_epoch = math.ceil(len(x_train) / BATCH_SIZE)\n# lr_schedule = WarmUpCosine(INITIAL_LR, epochs=EPOCHS, steps_per_epoch=steps_per_epoch, warmup_epochs=WARMUP_EPOCHS)\n\n# optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=MOMENTUM, nesterov=True)\n\n# # If you use categorical one-hot labels:\n# # loss_fn = tf.keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING)\n# # otherwise for integer labels:\n# # loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:52.766145Z","iopub.execute_input":"2025-11-25T01:11:52.766333Z","iopub.status.idle":"2025-11-25T01:11:52.777642Z","shell.execute_reply.started":"2025-11-25T01:11:52.766313Z","shell.execute_reply":"2025-11-25T01:11:52.776972Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# PART 12 — Compile the Mode\n\nConcept\n:\n\t•\tSGD + Momentum → stable, proven optimizer for CNNs\n\t•\tLabel smoothing → prevents model from becoming overconfident\n\t•\tCompile → tie the model, loss, and optimizer together before trainin","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.datasets import cifar100\n\n(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n\ny_train = y_train.squeeze()\ny_test = y_test.squeeze()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:52.778424Z","iopub.execute_input":"2025-11-25T01:11:52.778687Z","iopub.status.idle":"2025-11-25T01:11:55.121425Z","shell.execute_reply.started":"2025-11-25T01:11:52.778670Z","shell.execute_reply":"2025-11-25T01:11:55.120631Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"steps_per_epoch = len(x_train) // BATCH_SIZE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:55.122298Z","iopub.execute_input":"2025-11-25T01:11:55.122692Z","iopub.status.idle":"2025-11-25T01:11:55.126448Z","shell.execute_reply.started":"2025-11-25T01:11:55.122660Z","shell.execute_reply":"2025-11-25T01:11:55.125810Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def se_block(x, se_ratio=8):\n    filters = x.shape[-1]\n    se = tf.keras.layers.GlobalAveragePooling2D()(x)\n    se = tf.keras.layers.Dense(filters // se_ratio, activation='relu')(se)\n    se = tf.keras.layers.Dense(filters, activation='sigmoid')(se)\n    se = tf.keras.layers.Reshape((1,1,filters))(se)\n    return tf.keras.layers.multiply([x, se])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:55.127152Z","iopub.execute_input":"2025-11-25T01:11:55.127373Z","iopub.status.idle":"2025-11-25T01:11:55.798560Z","shell.execute_reply.started":"2025-11-25T01:11:55.127356Z","shell.execute_reply":"2025-11-25T01:11:55.797687Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"steps_per_epoch = len(x_train) // BATCH_SIZE\nlr_schedule = WarmUpCosine(INITIAL_LR, EPOCHS, steps_per_epoch)\n\noptimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=MOMENTUM, nesterov=True)\nloss_fn = tf.keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING)\n\nmodel = build_custom_cnn()\nmodel.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:55.799355Z","iopub.execute_input":"2025-11-25T01:11:55.799583Z","iopub.status.idle":"2025-11-25T01:11:56.097819Z","shell.execute_reply.started":"2025-11-25T01:11:55.799566Z","shell.execute_reply":"2025-11-25T01:11:56.096669Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/3811859484.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLABEL_SMOOTHING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_custom_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/2344242944.py\u001b[0m in \u001b[0;36mbuild_custom_cnn\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_custom_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_bn_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"],"ename":"NameError","evalue":"name 'layers' is not defined","output_type":"error"}],"execution_count":17},{"cell_type":"markdown","source":"# PART 13 — Callback\n\nConcept:\n\t•\tCheckpoint: saves your best weights\n\t•\tReduceLROnPlateau: lowers LR if loss stops improving\n\t•\tEarlyStopping: stops training early to prevent overfittin","metadata":{}},{"cell_type":"code","source":"callbacks = [\n    tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy'),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5),\n    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:56.098347Z","iopub.status.idle":"2025-11-25T01:11:56.098684Z","shell.execute_reply.started":"2025-11-25T01:11:56.098517Z","shell.execute_reply":"2025-11-25T01:11:56.098533Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Part 14: Train Model\n\nConcept:\n* Each epoch = full pass over train data\n* Validation used To Track Gen\n* Callback Help Tune Automatically While Training","metadata":{}},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:56.099824Z","iopub.status.idle":"2025-11-25T01:11:56.100106Z","shell.execute_reply.started":"2025-11-25T01:11:56.099987Z","shell.execute_reply":"2025-11-25T01:11:56.100001Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Use original integer labels y_train, y_test (shape (N,)) — do NOT one-hot encode\ntrain_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\ntrain_ds = train_ds.map(lambda x,y: (tf.cast(x, tf.float32)/255.0, y), num_parallel_calls=AUTOTUNE)\ntrain_ds = train_ds.map(preprocess_train, num_parallel_calls=AUTOTUNE)   # your augment fn must return (image, int_label)\ntrain_ds = train_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n\ntest_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\ntest_ds = test_ds.map(lambda x,y: (tf.cast(x, tf.float32)/255.0, y), num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n\n# Compile with sparse loss (no label smoothing available on older TF)\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\nmodel.compile(optimizer=optimizer, loss=loss_fn, metrics=['sparse_categorical_accuracy'])\n# or metrics=['accuracy'] — Keras will infer correct accuracy for sparse targets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:56.101373Z","iopub.status.idle":"2025-11-25T01:11:56.101619Z","shell.execute_reply.started":"2025-11-25T01:11:56.101512Z","shell.execute_reply":"2025-11-25T01:11:56.101523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1) Create optimizer with a float LR\noptimizer = tf.keras.optimizers.SGD(learning_rate=INITIAL_LR, momentum=MOMENTUM, nesterov=True)\n\n# 2) Define an epoch-based LR function (returns lr for given epoch)\ndef epoch_warmup_cosine(epoch):\n    # simple epoch-based schedule: linear warmup -> cosine decay across EPOCHS\n    warmup = WARMUP_EPOCHS\n    if epoch < warmup:\n        return float(INITIAL_LR * (epoch + 1) / warmup)  # +1 so epoch0 != 0\n    # cosine decay after warmup\n    progress = (epoch - warmup) / max(1, (EPOCHS - warmup))\n    cosine = 0.5 * (1.0 + math.cos(math.pi * min(1.0, progress)))\n    return float(INITIAL_LR * cosine)\n\n# 3) Use LearningRateScheduler (Keras will set optimizer.lr)\nlr_callback = tf.keras.callbacks.LearningRateScheduler(epoch_warmup_cosine, verbose=1)\n\n# 4) Use ReduceLROnPlateau as well (it will set lr when plateau occurs)\nreduce_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.5, patience=6, verbose=1, mode='min'\n)\n\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, mode='max', verbose=1),\n    lr_callback,\n    reduce_on_plateau\n]\n\nmodel.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:56.102597Z","iopub.status.idle":"2025-11-25T01:11:56.102804Z","shell.execute_reply.started":"2025-11-25T01:11:56.102703Z","shell.execute_reply":"2025-11-25T01:11:56.102712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    validation_data=test_ds,\n    epochs=EPOCHS,\n    callbacks=callbacks\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:56.103361Z","iopub.status.idle":"2025-11-25T01:11:56.104243Z","shell.execute_reply.started":"2025-11-25T01:11:56.104119Z","shell.execute_reply":"2025-11-25T01:11:56.104134Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**CHECK**","metadata":{}},{"cell_type":"code","source":"# 1) Print dataset batch shapes & label types\nxb, yb = next(iter(train_ds))\nprint(\"xb.shape, xb.min/max:\", xb.shape, float(tf.reduce_min(xb)), float(tf.reduce_max(xb)))\nprint(\"yb.shape, yb.dtype, unique labels (first 50):\", yb.shape, yb.dtype, tf.unique(tf.reshape(yb, [-1]))[0][:50])\n\n# 2) Show 6 images with labels (sanity)\nimport matplotlib.pyplot as plt\nfig, axes = plt.subplots(2,3, figsize=(9,6))\nfor i, ax in enumerate(axes.flatten()):\n    img = xb[i].numpy()\n    lbl = yb[i].numpy()\n    ax.imshow((img*255).astype('uint8') if img.max()<=1.0 else img.astype('uint8'))\n    ax.set_title(str(lbl))\n    ax.axis('off')\nplt.show()\n\n# 3) Model quick forward pass: check output shape & distribution\npreds = model.predict(xb[:64])\nprint(\"preds.shape:\", preds.shape)\nprint(\"preds min/max, mean:\", preds.min(), preds.max(), preds.mean())\nprint(\"argmax counts (first 64):\", np.bincount(np.argmax(preds, axis=1)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:56.105277Z","iopub.status.idle":"2025-11-25T01:11:56.105581Z","shell.execute_reply.started":"2025-11-25T01:11:56.105406Z","shell.execute_reply":"2025-11-25T01:11:56.105416Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PART 15 — Evaluate and Visualize\n\nConcept:\n\n\t•\tLoad best model checkpoint\n\t•\tEvaluate on unseen test set\n\t•\tExpect accuracy to gradually climb toward 60–65% with good tunin","metadata":{}},{"cell_type":"code","source":"model.load_weights('best_model.h5')\ntest_loss, test_acc = model.evaluate(test_ds)\nprint(\"Test Accuracy:\", test_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:11:56.107022Z","iopub.status.idle":"2025-11-25T01:11:56.107344Z","shell.execute_reply.started":"2025-11-25T01:11:56.107181Z","shell.execute_reply":"2025-11-25T01:11:56.107195Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# FULL","metadata":{}},{"cell_type":"code","source":"import os\n\nbase = \"/kaggle/input/cifar100\"\nprint(\"Base exists:\", os.path.exists(base))\nprint(\"Top-level entries in /kaggle/input/cifar100:\\n\")\nfor name in sorted(os.listdir(base)):\n    path = os.path.join(base, name)\n    entry_type = \"DIR\" if os.path.isdir(path) else \"FILE\"\n    print(f\" - {name:40s}  ({entry_type})\")\n\n# Recursively list first-level subfolders and detect train/test-like directories\nprint(\"\\nSearching for candidate train/test directories (depth=2)...\\n\")\ncandidates = []\nfor root, dirs, files in os.walk(base):\n    # skip very deep traversal, only go 3 levels max\n    depth = root[len(base):].count(os.sep)\n    if depth > 3:\n        continue\n    # count image-like files\n    img_count = sum(1 for f in files if f.lower().endswith(('.png','.jpg','.jpeg','.bmp')))\n    if img_count > 0 or any(d.islower() for d in dirs):\n        candidates.append((root, len(dirs), img_count))\n# print some candidates (limited)\nfor root, ndirs, nimgs in sorted(candidates, key=lambda x: (-x[2], x[1]))[:40]:\n    print(f\"{root:80s}  | subdirs: {ndirs:3d}  | image_files_in_folder: {nimgs:4d}\")\n\n# Try auto-detect train/test\ntrain_dir = None\ntest_dir = None\nfor root, dirs, files in os.walk(base):\n    name = os.path.basename(root).lower()\n    if name == \"train\" and train_dir is None:\n        train_dir = root\n    if name == \"test\" and test_dir is None:\n        test_dir = root\n\n# Fallback: if not found, try to find directories containing many class-folders\nif train_dir is None or test_dir is None:\n    # look for folders that contain many subdirs (likely class folders)\n    cand = []\n    for root, dirs, files in os.walk(base):\n        if len(dirs) >= 20:   # heuristic: CIFAR100 has 100 classes, but directory split may vary\n            cand.append((root, len(dirs)))\n    cand = sorted(cand, key=lambda x: -x[1])\n    if cand:\n        print(\"\\nFolders that look like they contain class subfolders (candidates):\")\n        for r, nd in cand[:6]:\n            print(f\" - {r}  (subdirs: {nd})\")\n        # pick best candidate for train if explicit train/test not found\n        if train_dir is None:\n            train_dir = cand[0][0]\n\nprint(\"\\nRecommended values (if not None):\")\nprint(\"TRAIN_DIR =\", train_dir)\nprint(\"TEST_DIR  =\", test_dir)\n\nprint(\"\\nIf TRAIN_DIR/TEST_DIR are None or incorrect, paste the printed candidate paths here.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:38:44.396189Z","iopub.execute_input":"2025-11-25T01:38:44.397042Z","iopub.status.idle":"2025-11-25T01:38:44.411238Z","shell.execute_reply.started":"2025-11-25T01:38:44.397008Z","shell.execute_reply":"2025-11-25T01:38:44.410528Z"}},"outputs":[{"name":"stdout","text":"Base exists: True\nTop-level entries in /kaggle/input/cifar100:\n\n - test                                      (FILE)\n - train                                     (FILE)\n\nSearching for candidate train/test directories (depth=2)...\n\n\nRecommended values (if not None):\nTRAIN_DIR = None\nTEST_DIR  = None\n\nIf TRAIN_DIR/TEST_DIR are None or incorrect, paste the printed candidate paths here.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Kaggle-ready CIFAR-100 training cell\n# Assumes you uploaded folders: \n#   /kaggle/input/cifar100/train  (has class subfolders)\n#   /kaggle/input/cifar100/test   (has class subfolders)\n# If your test folder path differs, update TEST_DIR below.\n\nimport os\nimport math\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers\nimport matplotlib.pyplot as plt\n\n# --------- CONFIG ----------\nTRAIN_DIR = '/kaggle/input/cifar100/train'\nTEST_DIR  = '/kaggle/input/cifar100/test'   # change if different\nBATCH_SIZE = 128\nIMG_SIZE = (32, 32)\nNUM_CLASSES = 100\nEPOCHS = 60\nINITIAL_LR = 0.1\nMOMENTUM = 0.9\nWARMUP_EPOCHS = 5\nSEED = 42\nAUTOTUNE = tf.data.AUTOTUNE\n\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\n\n# --------- Load datasets from directories (labels are integer indices) ----------\nprint(\"Loading datasets from directories...\")\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    TRAIN_DIR,\n    labels=\"inferred\",\n    label_mode=\"int\",\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=SEED\n)\n\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n    TEST_DIR,\n    labels=\"inferred\",\n    label_mode=\"int\",\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)\n\nclass_names = train_ds.class_names\nprint(\"Classes:\", len(class_names))\n\n# --------- Simple preprocessing and augmentation layers (Keras preprocessing) ----------\n# We'll only do small augmentations to avoid breaking ranges.\ndata_augment = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomTranslation(0.04, 0.04),   # small shift\n    # small random brightness/contrast can be added if desired:\n    # layers.RandomContrast(0.08),\n], name=\"data_augmentation\")\n\ndef preprocess_train(image, label):\n    image = tf.cast(image, tf.float32) / 255.0  # IMPORTANT: scale once to [0,1]\n    image = data_augment(image)\n    return image, label\n\ndef preprocess_eval(image, label):\n    image = tf.cast(image, tf.float32) / 255.0\n    return image, label\n\ntrain_ds = train_ds.map(preprocess_train, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\ntest_ds  = test_ds.map(preprocess_eval, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n\n# Quick visual check (first batch)\nprint(\"\\nSanity check: sample images from train batch\")\nxb, yb = next(iter(train_ds))\nprint(\"batch shapes:\", xb.shape, yb.shape, \"min/max:\", xb.numpy().min(), xb.numpy().max())\nfig, axes = plt.subplots(2,6, figsize=(12,4))\naxes = axes.flatten()\nfor i, ax in enumerate(axes):\n    ax.imshow((xb[i].numpy()*255).astype('uint8'))\n    ax.set_title(int(yb[i].numpy()))\n    ax.axis('off')\nplt.show()\n\n# --------- Model: small ResNet-like (compact to run on Kaggle quickly) ----------\ndef conv_bn_relu(x, filters, kernel_size=3, stride=1):\n    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same', use_bias=False,\n                      kernel_regularizer=regularizers.l2(1e-4))(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n    return x\n\ndef residual_block(x, filters, stride=1):\n    shortcut = x\n    out = conv_bn_relu(x, filters, 3, stride)\n    out = layers.Conv2D(filters, 3, padding='same', use_bias=False,\n                        kernel_regularizer=regularizers.l2(1e-4))(out)\n    out = layers.BatchNormalization()(out)\n    if stride != 1 or x.shape[-1] != filters:\n        shortcut = layers.Conv2D(filters, 1, strides=stride, padding='same', use_bias=False,\n                                 kernel_regularizer=regularizers.l2(1e-4))(shortcut)\n        shortcut = layers.BatchNormalization()(shortcut)\n    out = layers.add([out, shortcut])\n    out = layers.ReLU()(out)\n    return out\n\ndef build_model(input_shape=(32,32,3), num_classes=100, dropout_rate=0.3):\n    inputs = layers.Input(shape=input_shape)\n    x = conv_bn_relu(inputs, 64, 3)\n    x = residual_block(x, 64)\n    x = residual_block(x, 128, stride=2)\n    x = residual_block(x, 128)\n    x = residual_block(x, 256, stride=2)\n    x = residual_block(x, 256)\n    # global pooling (avg)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n    x = layers.Dropout(dropout_rate)(x)\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n    model = models.Model(inputs, outputs, name='cifar_custom_resnet')\n    return model\n\nmodel = build_model(input_shape=(32,32,3), num_classes=len(class_names))\nmodel.summary()\n\n# --------- Epoch-based warmup + cosine LR scheduler (returns float per epoch) ----------\ndef epoch_warmup_cosine(epoch):\n    # epoch is 0-indexed\n    if epoch < WARMUP_EPOCHS:\n        # linear warmup\n        return float(INITIAL_LR * (epoch + 1) / WARMUP_EPOCHS)\n    else:\n        progress = (epoch - WARMUP_EPOCHS) / max(1, (EPOCHS - WARMUP_EPOCHS))\n        cosine = 0.5 * (1.0 + math.cos(math.pi * min(1.0, progress)))\n        return float(INITIAL_LR * cosine)\n\n# Make optimizer with float lr so callbacks that set lr are allowed\noptimizer = tf.keras.optimizers.SGD(learning_rate=INITIAL_LR, momentum=MOMENTUM, nesterov=True)\n\n# Use sparse loss (integers from image_dataset_from_directory)\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n\n# Compile\nmodel.compile(optimizer=optimizer, loss=loss_fn, metrics=['sparse_categorical_accuracy'])\n\n# --------- Callbacks ----------\ncheckpoint_path = '/kaggle/working/best_model.h5'\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_sparse_categorical_accuracy',\n                                       save_best_only=True, mode='max', verbose=1),\n    tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', patience=20,\n                                     restore_best_weights=True, mode='max', verbose=1),\n    tf.keras.callbacks.LearningRateScheduler(epoch_warmup_cosine, verbose=1)\n]\n\n# --------- Train ----------\nhistory = model.fit(\n    train_ds,\n    validation_data=test_ds,\n    epochs=EPOCHS,\n    callbacks=callbacks,\n    verbose=2\n)\n\n# --------- Evaluate final model ----------\nprint(\"\\nLoading best checkpoint and evaluating on test set:\")\nmodel.load_weights(checkpoint_path)\nres = model.evaluate(test_ds, verbose=2)\nprint(\"Test loss, Test sparse accuracy:\", res)\n\n# Save the final model in Keras format (optional)\nmodel.save('/kaggle/working/custom_cifar100_model.keras')\nprint(\"Saved model to /kaggle/working/custom_cifar100_model.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T01:33:31.132643Z","iopub.execute_input":"2025-11-25T01:33:31.133213Z","iopub.status.idle":"2025-11-25T01:33:31.164099Z","shell.execute_reply.started":"2025-11-25T01:33:31.133191Z","shell.execute_reply":"2025-11-25T01:33:31.163245Z"}},"outputs":[{"name":"stdout","text":"Loading datasets from directories...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/3272525036.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# --------- Load datasets from directories (labels are integer indices) ----------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading datasets from directories...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m train_ds = tf.keras.utils.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inferred\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/image_dataset_utils.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     image_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"inferred\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mlist_directory_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    766\u001b[0m   \"\"\"\n\u001b[1;32m    767\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m     raise errors.NotFoundError(\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0mnode_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: Could not find directory /kaggle/input/cifar100/train"],"ename":"NotFoundError","evalue":"Could not find directory /kaggle/input/cifar100/train","output_type":"error"}],"execution_count":23}]}